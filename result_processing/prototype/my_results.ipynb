{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import json\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "plt.rcParams['font.size'] = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 100\n",
    "frac = 0.1\n",
    "local_ep = 1\n",
    "unbalanced = True\n",
    "\n",
    "global_ep = 1000\n",
    "\n",
    "shard_per_user = 2\n",
    "\n",
    "#dataset = 'mnist'\n",
    "dataset = 'cifar10'\n",
    "# dataset = 'cifar100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'mnist':\n",
    "    model = 'mlp'\n",
    "else:\n",
    "    model = 'cnn'\n",
    "\n",
    "iid = False\n",
    "if unbalanced:\n",
    "    data_dict_fname = 'unbalanced_dict_users_2.pkl'\n",
    "else:\n",
    "    data_dict_fname = 'shared_dict_users.pkl'\n",
    "\n",
    "    if shard_per_user == 10:\n",
    "        iid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\\mnist\\mlp_iidTrue_num100_C0.1_le1\\shard10\\run1\\fed\n",
    "base_dir = './save/{}/{}_iid{}_num{}_C{}_le{}/shard{}/'.format(\n",
    "    dataset, model, iid, num_users, frac, local_ep, shard_per_user)\n",
    "runs = os.listdir(base_dir)\n",
    "print(runs)\n",
    "#runs = ['selection'] # diff data distribution\n",
    "#runs = ['selection1', 'selection2', 'selection3', 'selection4', 'selection5']\n",
    "#runs = ['selection1']\n",
    "runs = ['cossim1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_path = os.path.join(base_dir, data_dict_fname)\n",
    "with open(data_dict_path, 'rb') as handle:\n",
    "    (dict_users_train, dict_users_test, _) = pickle.load(handle)\n",
    "local_data_size = []\n",
    "for idx in range(num_users):\n",
    "    local_data_size.append(len(dict_users_train[idx]))\n",
    "print('local dataset size: ', local_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_cnt = np.zeros(100)\n",
    "slct_cnt = np.zeros(100)\n",
    "max_ut = np.zeros(100)\n",
    "\n",
    "def animate(i):\n",
    "    #print(raw_ut[i])\n",
    "    utility = json.loads(raw_ut[i])\n",
    "    #print(utility)\n",
    "    for j,(k,v) in enumerate(utility.items()):\n",
    "        k_int = int(k)\n",
    "        v_float = float(v)\n",
    "        if v_float > max_ut[k_int]: max_ut[k_int] = v_float\n",
    "        if i == 0:\n",
    "            rand_cnt[k_int] += 1\n",
    "        else:\n",
    "            if j < 5:\n",
    "                slct_cnt[k_int] += 1\n",
    "            else:\n",
    "                rand_cnt[k_int] += 1\n",
    "               \n",
    "    #rand_bar.set_data(range(num_users), rand_cnt)\n",
    "    #slct_bar.set_data(range(num_users), slct_bar)\n",
    "    return \n",
    "    \n",
    "def plot_selection(fp):\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = fig.gca()\n",
    "    \n",
    "    global raw_ut\n",
    "    raw_ut = fp.readlines()\n",
    "    \n",
    "    for t in range(global_ep-1):\n",
    "        animate(t)\n",
    "    #ani = animation.FuncAnimation(fig=fig, func=animate, frames=2000, interval=1000/N, blit=True, repeat=True)\n",
    "    rand_bar = ax.bar(range(num_users), rand_cnt, width=0.5, label='rand')\n",
    "    slct_bar = ax.bar(range(num_users), slct_cnt, width=0.5, label='slct', bottom=rand_cnt)\n",
    "    for c in range(num_users):\n",
    "        ax.text(c, rand_cnt[c]+slct_cnt[c]+1000/(slct_cnt[c]+8), \"{:.2f}\".format(max_ut[c]), color='gray', va='center', rotation=90, fontsize=15)\n",
    "    ax.set_xlabel('client ID', fontsize=14)\n",
    "    ax.set_ylabel('count', fontsize=14)\n",
    "    ax.set_ylim([0, 2000])\n",
    "    ax.legend()\n",
    "    #plt.title('selection cnt - ' + str(shard_per_user) + ' class per client')\n",
    "    plt.title('selection cnt - shard' + str(shard_per_user))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc_fed = np.zeros(len(runs))\n",
    "acc_statsel = np.zeros(len(runs))\n",
    "acc_local_localtest = np.zeros(len(runs))\n",
    "acc_local_newtest_avg = np.zeros(len(runs))\n",
    "acc_local_newtest_ens = np.zeros(len(runs))\n",
    "lg_metrics = {}\n",
    "\n",
    "fig, axs = plt.subplots(len(runs)+1, sharex=True, figsize=(20, 12))\n",
    "fig.suptitle('dataset size | selection cnt - shard' + str(shard_per_user))\n",
    "axs[0].plot(range(len(local_data_size)), local_data_size,label='local data size')\n",
    "\n",
    "for idx, run in enumerate(runs):\n",
    "    print('=== ', run, ' ===')\n",
    "    # FedAvg\n",
    "    base_dir_fed = os.path.join(base_dir, \"{}/fedavg_cossim\".format(run))\n",
    "    if os.path.exists(base_dir_fed):\n",
    "        results_path_fed = os.path.join(base_dir_fed, \"results.csv\")\n",
    "        cossim_path_fed = os.path.join(base_dir_fed, \"cossim_glob_uni.csv\")\n",
    "        cossim_glob_uni_fed = np.genfromtxt(cossim_path_fed, delimiter=',')\n",
    "        \n",
    "        df_fed = pd.read_csv(results_path_fed)\n",
    "        df_fed['cossim_glob_uni'] = cossim_glob_uni_fed\n",
    "        print(df_fed.head())\n",
    "        df_fed = df_fed[:global_ep]\n",
    "        print(df_fed.shape)\n",
    "        acc_fed[idx] = df_fed.loc[df_fed.shape[0]-1]['best_acc']\n",
    "        print('fedavg, best_acc', acc_fed[idx], '===================')\n",
    "        print('')\n",
    "    else:\n",
    "        print('No random selection training result.')\n",
    "\n",
    "    # fedavg w/ utility selection\n",
    "    base_dir_statsel = os.path.join(base_dir, \"{}/utility_cossim\".format(run))\n",
    "    if os.path.exists(base_dir_statsel):\n",
    "        results_path_statsel = os.path.join(base_dir_statsel, \"results.csv\")\n",
    "        slctcnt_path = os.path.join(base_dir_statsel, \"selection_cnt.csv\")\n",
    "        cossim_path_statsel = os.path.join(base_dir_statsel, \"cossim_glob_uni.csv\")\n",
    "        utility_path = os.path.join(base_dir_statsel, \"utility.csv\")\n",
    "        df_statsel = pd.read_csv(results_path_statsel)\n",
    "        slctcnt = np.genfromtxt(slctcnt_path, delimiter=',')\n",
    "        cossim_glob_uni_statsel = np.genfromtxt(cossim_path_statsel, delimiter=',')\n",
    "        df_statsel['cossim_glob_uni'] = cossim_glob_uni_statsel\n",
    "        \n",
    "        #utility = np.genfromtxt(utility_path, delimiter='\\n')\n",
    "\n",
    "        print(df_statsel.head())\n",
    "        df_statsel = df_statsel[:global_ep]\n",
    "        print(df_statsel.shape)\n",
    "        acc_statsel[idx] = df_statsel.loc[df_statsel.shape[0]-1]['best_acc']\n",
    "        print('statsel, best_acc', acc_statsel[idx], '===================')\n",
    "        print('')\n",
    "    else:\n",
    "        print('No utility selection training result.')\n",
    "\n",
    "\n",
    "    #['loss_avg', 'loss_test', 'acc_test', 'best_acc']\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "    metrics = [('loss_avg',[0, 2.5]), \n",
    "               ('acc_test', [0, 100]), \n",
    "               ('best_acc', [0, 100]),\n",
    "               ('cossim_glob_uni', [0, 1])]\n",
    "    \n",
    "    for col, yl in metrics:\n",
    "        for x in ['epoch', 'time_simu']:\n",
    "            plt.figure()\n",
    "            if os.path.exists(base_dir_fed):\n",
    "                #plt.plot(df_fed[x], df_fed[col], label='random', marker='^')\n",
    "                plt.plot(df_fed[x], df_fed[col], label='random')\n",
    "            if os.path.exists(base_dir_statsel):\n",
    "                #plt.plot(df_statsel[x], df_statsel[col], label='utility', marker='.')\n",
    "                plt.plot(df_statsel[x], df_statsel[col], label='utility')\n",
    "            plt.legend()\n",
    "            plt.ylabel(col)\n",
    "            plt.xlabel(x)\n",
    "            plt.ylim(yl)\n",
    "            plt.title(run + ' - shard' + str(shard_per_user))\n",
    "            #plt.title(run + ' - ' + str(shard_per_user) + ' class per client')\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.bar(range(len(slctcnt)), slctcnt)\n",
    "    plt.ylabel('selection cnt')\n",
    "    plt.xlabel('client id')\n",
    "    \n",
    "    axs[idx+1].bar(range(len(slctcnt)), slctcnt)\n",
    "    '''\n",
    "    with open(utility_path) as fp_utility:\n",
    "        plot_selection(fp_utility)\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "#plt.rcParams['font.size'] = 22\n",
    "plt.figure()\n",
    "plt.title('final acc')\n",
    "plt.plot(range(len(acc_fed)), acc_fed, label='random')    \n",
    "plt.plot(range(len(acc_statsel)), acc_statsel, label='utility')\n",
    "plt.xlabel('run')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot t_i\n",
    "ti_path = './save/user_config/var_time/{}_{}.csv'.format(dataset, num_users)\n",
    "ti_all = np.genfromtxt(ti_path, delimiter=',')\n",
    "\n",
    "plt.figure()\n",
    "for ep in range(10):\n",
    "    plt.plot(range(num_users), ti_all[:, ep], label='round'+str(ep))\n",
    "    plt.legend()\n",
    "\n",
    "print(ti_all[:,0])\n",
    "plt.figure()\n",
    "for user in range(2):\n",
    "    plt.plot(range(global_ep), ti_all[user], label='client'+str(user))\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Run\", \"Local Test\", \"New Test (avg)\", \"New Test (ens)\", \"FedAvg Rounds\", \"LG Rounds\"]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_acc_local_localtest = \"{:.2f} +- {:.2f}\".format(acc_local_localtest.mean(), acc_local_localtest.std())\n",
    "str_acc_local_newtest_avg = \"{:.2f} +- {:.2f}\".format(acc_local_newtest_avg.mean(), acc_local_newtest_avg.std())\n",
    "str_acc_local_newtest_ens = \"{:.2f} +- {:.2f}\".format(acc_local_newtest_ens.mean(), acc_local_newtest_ens.std())\n",
    "\n",
    "print(\"localonly:\\t\", str_acc_local_localtest)\n",
    "print(\"localonly_avg:\\t\", str_acc_local_newtest_avg)\n",
    "print(\"localonly_ens:\\t\", str_acc_local_newtest_ens)\n",
    "\n",
    "results.append([\"LocalOnly\", str_acc_local_localtest, str_acc_local_newtest_avg, str_acc_local_newtest_ens, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lg_run in sorted(lg_metrics.keys()):\n",
    "    x = [\"LG-FedAvg\"]\n",
    "    print(lg_run)\n",
    "    for array in ['acc_local', 'acc_avg', 'acc_ens']:\n",
    "        mean = lg_metrics[lg_run][array].mean()\n",
    "        std = lg_metrics[lg_run][array].std()\n",
    "        str_acc = \"{:.2f} +- {:.2f}\".format(mean, std)\n",
    "        print(\"{}:\\t{}\".format(array, str_acc))\n",
    "        \n",
    "        x.append(str_acc)\n",
    "    x.append(lg_run)\n",
    "    x.append(rd_lg)\n",
    "    results.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_acc_fed = \"{:.2f} +- {:.2f}\".format(acc_fed.mean(), acc_fed.std())\n",
    "print(\"fed:\\t\", str_acc_fed)\n",
    "results.append([\"FedAvg\", str_acc_fed, str_acc_fed, str_acc_fed, rd_fed, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results, columns=columns).set_index(\"Run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
